
<!-- Post Layout Start -->

<!DOCTYPE html>
<html lang="en">

  
<!-- HEAD Start -->

<head>
  


  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Website of Nicolas Six">
  <meta name="author" content="Nicolas Six">
  <meta name="keywords" content="Nicolas, Six">
  <link rel="canonical" href="/master-thesis/">
  <title>Nicolas Six | Traffic sign detection on mobile device</title>

  <!-- Bootstrap Core CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

  <!-- Custom CSS -->
  <link href="/css/grayscale.css" rel="stylesheet">
  

  <!-- Custom Fonts -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/rrssb.css" />
  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->
  
    <link rel="shortcut icon" type="image/x-icon" href="/img/brain_bw_16p.png">
  

  

  


  <!-- iOS Web App mode -->

  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="apple-touch-icon" sizes="36x36" href="/img/web-app/icon-36p.png">
  <link rel="apple-touch-icon" sizes="48x48" href="/img/web-app/icon-48p.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/img/web-app/icon-72p.png">
  <link rel="apple-touch-icon" sizes="96x96" href="/img/web-app/icon-96p.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/img/web-app/icon-144p.png">
  <link rel="apple-touch-icon" sizes="192x192" href="/img/web-app/icon-192p.png">

  <!-- Android Web App mode -->

  <link rel="manifest" href="/manifest.json">




  
<!-- Chrome, Firefox OS and Opera -->
<meta name="theme-color" content="#000000">
<!-- Windows Phone -->
<meta name="msapplication-navbutton-color" content="#000000">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">


  


  <!-- Syntax highlight in post pages -->

  <link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.2/styles/monokai_sublime.min.css">




</head>

<!-- HEAD End -->


  <body style="background-image:url(/img/thesis.png);background-repeat:no-repeat;background-position: top center;background-size: 100%;">

    
<!-- Navigation Start -->

<nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
        <i class="fa fa-bars"></i>
      </button>
      
        <a class="navbar-brand" href="/">
      
          <div>
            
              <img src="/img/brain_bw_16p.png" alt="">
            
            Nicolas Six
          </div>
        </a>
    </div>
    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
      <ul class="nav navbar-nav">
        
          <!-- Blog, Post, Tag and Error pages -->
          
            <li>
            
                <a href="/#about"> About </a>
            
            </li>
          
            <li>
            
                <a href="/#timeline"> Education </a>
            
            </li>
          
            <li>
            
                <a href="/#projects"> Projects </a>
            
            </li>
          
            <li>
            
                <a href="/#contact"> Contact </a>
            
            </li>
          
        
      </ul>
    </div>
  </div>
</nav>

<!-- Navigation End -->

<!--     <img style="width:100%;overflow:hidden;" class="project-img" src="/img/thesis.png" alt=""> -->
    
    <section id="post" class="container content-section text-center" style="margin-top:40%;padding-top:30px;background:black;box-shadow: 6px 6px 6px rgba(0,0,0,0.75)">
      
      <div class="row">
        <div class="col-md-10 col-md-offset-1">

          
<!-- Swipe Instructions Start -->

<div id="swipe-instruction">
  <div>
    <p><br><br><br></p>
    <i id="hand-swipe" class="fa fa-hand-o-up"></i>
    <p><strong>
    
      Did you know that you can navigate the posts by swiping left and right?
    
    </strong></p>
    <button type="button" class="btn btn-default ok-btn close-swipe-instruction">
      
        Awesome!
      
    </button>
  </div>
</div>

<!-- Swipe Instructions End -->


          <h1><strong>Traffic sign detection on mobile device</strong></h1>
          <iframe src="https://ghbtns.com/github-btn.html?user=anliec&repo=keras-cv&type=watch&count=true&size=large&v=2" frameborder="0" scrolling="0" width="160px" height="30px"></iframe>
          <iframe src="https://ghbtns.com/github-btn.html?user=anliec&repo=keras-cv&type=star&count=true&size=large&v=2" frameborder="0" scrolling="0" width="160px" height="30px"></iframe>

          <section class="text-justify" style="margin-top:30px">
            <h3 id="introduction">Introduction</h3>

<p>This work started by a simple conclusion: state of the art are very good at detecting complex object in complex environment. However, they need a lot of resources to run. While traffic sign are made to be detected, they have bright colors, clear shape, are always seen from the same angle… Is it needed to have a complex feature extractor to properly detect them? In this work I focused of US warning sign, but it’s easy to extant and reproduce the results to other kind of signs.</p>

<p>This project was part of my Master thesis at the Georgia Institute of Technology. My goal was to improve over my GRA work, and bring the traffic sign detection directly to a smartphone, saving energy, storage space and making the process much easier to run. If you want more detail about the global project, please check my post <a href="/traffic-sign-mapping/">here</a>.</p>

<p>In this page I will try to summarize months of work in a readable format. However, for more detailed information I advise you to check my <a href="https://github.com/anliec/keras-cv/blob/master/reports/dissertation/thesis.pdf">dissertation</a> and <a href="https://github.com/anliec/keras-cv/blob/master/reports/presentation/Thesis___presentation.pdf">slides</a>.</p>

<h3 id="idea">Idea</h3>

<h4 id="object-complexity">Object complexity</h4>

<p>As already stated in the introduction, traffic sign should be much easier to detect than let say an owl, which is one of the class of the MS COCO dataset from which come the image bellow.</p>

<p><img src="/img/difficult_detection.jpg" alt="owl image" /></p>

<p>On the other side, even on poor conditions, traffic sign are always very easy to see.</p>

<p><img src="/img/example_bad_image.jpg" alt="traffic sign image" /></p>

<p>To make our Convolutionnal Neural Network (CNN) faster, we can hope that this will translate into features that are easier to learn by the network and more importantly require less filters and less layers to be properly extracted.</p>

<p>For a quick demonstration of how easy it is to get good feature extraction for traffic sign, let use the following image as a base.</p>

<p><img src="/img/base_image_small.jpg" alt="" /></p>

<p>Now generate some very basic yellow edges detection filters.</p>

<p><img src="/img/filters.png" alt="" /></p>

<p>Applying them on the image directly extract all the important features of the sign with very few noise, as you can see on the figure bellow.</p>

<p><img src="/img/filter_res.png" alt="" /></p>

<p>This is obviously only a toy example and if building hand crafted filters for traffic sign detection have been the focus of lot of research in the past the results have always been far from perfect.</p>

<p>However, it does show that using over 50 layers as a feature extraction backbone does not make sens in a traffic sign context.</p>

<h4 id="object-shape">Object shape</h4>

<p>Now that we beleive that the object we are look at are not very complex, can we take advantage of any other features to make the detection easier?</p>

<p>State of the art one shot object detection CNN, as of 2020, use anchors box to set base shape of the objects the network is trying to detect. Bellow is an illustration of how Yolo v3 do it.</p>

<p><img src="/img/anchors.png" alt="" /></p>

<p>So for each prediction, Yolo v3 predict, in addition to the object class, four values. To predict the offset to the center of the detection cell and to scale the anchor shape to the best shape.</p>

<p>Let’s look at the object we are trying to detect:</p>

<p><img src="/img/classes_diamond_nocount.jpg" alt="traffic sign classes" /></p>

<p>You can see that this object always fit very well into a square bounding box. Because of there usage on the road, we always saw them from the front, with very few perspective distortion. Making the two parameters for sizing the the anchor redundant.</p>

<p>In addition, in this study we took the assumption that size and position are hard to predict for a CNN. This come from observation of the accuracy of tiny-Yolo compared to Yolo, most of the time the prediction made by tiny-Yolo are correct, but the bounding box is not very accurate. In our case we don’t really want pixel accurate bounding box. We just want to detect if there is a traffic sign on the image, have an approximate position and size. If we want more detail we can run a post process with this information, but being able to quickly filter over 90% of the frame that does not have a sign is crucial for real life application.</p>

<p>With that in mind, we decided not to predict this four different parameters and just to use the anchor directly. Using five different anchors allowed us to get a very good overlap with the signs on the images.</p>

<h3 id="datas">Datas</h3>

<p>The data used for this study are of two kind. First, we used real data profited by the lab, but as this data are limited in quantity and cost a lot to get, I also generated some artificial data, used as a first training set, before fine tuning on the real data.</p>

<h4 id="real-data">Real Data</h4>

<p>This dataset of 8,719 image manually annotated from image recorded in Georgia and surrounding area. The image were collected using two different means, a smartphone camera or a sensing vehicle with specialized equipment. Please refer to the Appendix of <a href="https://github.com/anliec/keras-cv/blob/master/reports/dissertation/thesis.pdf">my thesis</a> for more information.</p>

<h4 id="artificial-data">Artificial data</h4>

<p>Even with data heavy augmentation and dropout, 8,719 image are not enough to train a CNN from scratch. Instead of training the backbone on a classical image classification task, such as ImageNet, as it is usually done, we chose here to generate artificial data for two reasons. First, because we can generate this kind of data easily. Second, because using this data allow us to specialize the filters directly and so allow us to use as few filter as possible right at the beginning.</p>

<p>To generate this data, we chose a very basic approach. We fill an image with random polygons with colors sampled from the color distribution of the real data. On top of this image we draw a set of yellow square rotated by 45 degree, as well as a set of not rotated square as negative example. An example of an image generated that way is given bellow.</p>

<p><img src="/img/fake_data_ex.jpg" alt="" /></p>

<p>This image is not designed to be realistic. However, it does allow to train a yellow square detector on a noisy background, which is what we care about at that point.</p>

<p>Lot of implementation details are not given here, <a href="https://github.com/anliec/keras-cv/blob/master/reports/dissertation/thesis.pdf">my thesis</a> will give you more information, you can also check the generation code <a href="https://github.com/anliec/keras-cv/blob/master/generate_data.py">here</a>.</p>

<h3 id="architecture">Architecture</h3>

<p>The architecture used in this work is very similar to the one of SSD, with a loss function directly derived from it and a custom backbone. A complete description of this architecture is out of scope of this article. However, interested reader are strongly encouraged to check my <a href="https://github.com/anliec/keras-cv/blob/master/reports/dissertation/thesis.pdf">thesis dissertation</a> or the <a href="https://github.com/anliec/keras-cv/blob/master/load_network.py">source code</a>.</p>

<p><img src="/img/thesis_bg.png" alt="CNN architecture" /></p>

<p>The image above is a graphical representation of the final architecture. Each yellow block represent a layer, the red region being the input size when strides are involved. You can see the five final output layers, one for each anchor.</p>

<p>During this study different kind of block were tested. From the classical 2D convolution to residual convolution and inverted residual block. But the residual convolution showed the best results in our experiment and is the one we chose to use here.</p>

<h3 id="results">Results</h3>

<p>We will now give you a quick overview of the results we get from this model. As the focus of this study is to reach the best speed possible, let me start by presenting the accuracy evolution with speed of this model. We are going to use here two different accuracy metrics, map@25 and map@50 (mean average precision at 25% IoU and 50% IoU respectively). We here use very low IoU threshold because of our problem definition, according to our assumption we don’t target very accurate bounding box.</p>

<p>As a comparison, we also plot the value for tiny-Yolo v3, trained on the same dataset.</p>

<p>The different point in the plot represent different input size for tiny-Yolo and different filter count for our architecture.</p>

<p><img src="/img/map_at_25_fps_models.png" alt="" /> <img src="/img/map_at_25_latency_models.png" alt="" /></p>

<p><img src="/img/map_at_50_fps_models.png" alt="" /> <img src="/img/map_at_50_latency_models.png" alt="" /></p>

<p>You can see that if our architecture does not surpass Yolo accuracy. It does reach comparable map score while being an order of magnitude faster.</p>

<p>To give you a better idea of what this results mean, bellow are some example of detection as done by the architecture.</p>

<p><img src="/img/FN03.png" alt="" /></p>

<p>Case of a warning sign not detected on a curve.</p>

<p><img src="/img/FP04.jpg" alt="" /></p>

<p>Case of a sign detected while not being of the right class.</p>

<p><img src="/img/TP04.jpg" alt="" /></p>

<p>Case of an obstructed sign correctly detected.</p>

<p>More example example and comment about them are available for the interested reader in my <a href="https://github.com/anliec/keras-cv/blob/master/reports/dissertation/thesis.pdf">thesis dissertation</a>.</p>

<h3 id="conclusion">Conclusion</h3>

<p>I really enjoyed working on this problem as it allowed me to take the time to thing about a complete architecture, taking into account the specific problem I was solving and the hardware I was given to use. It also allowed me to better see the effect of multiple parameters such as dropout, weight regularization, loss, activation function… Skills that I’m looking forward to continue to use in the future.</p>

<!-- A longer description about the project is on the way, check the Github page for more information! -->


          </section>

          
<!-- Share Buttons Start -->
<div>
  <ul class="rrssb-buttons clearfix">
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

<!-- Share Buttons End -->


          <hr />

          
          <div class="author row">
            <img class="col-xs-4 col-sm-3 col-md-2" src="/img/profile.jpg" alt="Me" />
            <p class="col-xs-8 col-sm-9 col-md-10">
              Nicolas Six is a Computer Science engineer passionate about machine learning and robotic.
            </p>
          </div>
          
        </div>
      </div>
    </section>

    <!-- Footer Start -->

<footer>

    <!-- Social Buttons Start -->

<ul class="list-inline social-buttons">
    
    <li><a href="https://github.com/anliec" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
    
    <li><a href="https://www.linkedin.com/in/nicolas-six-a1457a112/" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
    
    <li><a href="mailto:nicolas.six@gatech.edu" target="_blank"><i class="fa fa-envelope fa-fw"></i></a></li>
    
    <li><a href="tel:+1-334-731-8262" target="_blank"><i class="fa fa-phone fa-fw"></i></a></li>
    
    
</ul>

<!-- Social Buttons End -->


    <p><br><br></p>

    <div class="container text-center">
        <p>Copyright &copy; Nicolas Six 2020</p>
        
    </div>
</footer>

<p><br><br><br><br><br><br></p>

<!-- Footer End -->


    
<!-- Javascript Start -->

<!-- jQuery -->
<script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

<!-- Custom Theme JavaScript -->
<!--* Start Bootstrap - Grayscale Bootstrap Theme (http://startbootstrap.com)
* Code licensed under the Apache License v2.0.
* For details, see http://www.apache.org/licenses/LICENSE-2.0.-->
<script>
function toggleNavCollapse(){50<$(".navbar").offset().top?$(".navbar-fixed-top").addClass("top-nav-collapse"):$(".navbar-fixed-top").removeClass("top-nav-collapse");}
$(document).ready(toggleNavCollapse);
$(window).scroll(toggleNavCollapse);$(function(){$("a.page-scroll").bind("click",function(b){var a=$(this);$("html, body").stop().animate({scrollTop:$(a.attr("href")).offset().top-50},1500,"easeInOutExpo",function(){a.blur()});b.preventDefault()})});$(".navbar-collapse ul li a").click(function(){$(".navbar-toggle:visible").click()});
</script>





  <!-- Syntax highlight in post pages-->

  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.2/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>




  

  <!-- Google Tracking Id Start -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>

  <!-- Google Tracking Id End -->

  




  <!-- Disqus -->

  

    <script type="text/javascript">
    var disqus_shortname = 'personal-jekyll-theme';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>

  

  

    <!-- Comments Counter Start -->

    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'personal-jekyll-theme'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
    </script>

    <!-- Comments Counter End -->

  





  <!-- Share buttons Start -->

  <script src="/js/rrssb.min.js"></script>

  <!-- Share buttons End -->





<script>
function addTohistory() {
  if (!window.location.host.startsWith("127.0.0.1")) {
    history.pushState({}, 'Traffic sign detection on mobile device', 'https://anliec.github.io//master-thesis/');
  }
}
</script>

<!-- Gesture Navigation / Swipe Instruction Start -->


<!-- Javascript End -->


  </body>
</html>

<!-- Post Layout End -->
